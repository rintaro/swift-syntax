//// Automatically generated by generate-swift-syntax
//// Do not edit directly!
//===----------------------------------------------------------------------===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2014 - 2023 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//

@_spi(RawSyntax) @_spi(ExperimentalLanguageFeatures) import SwiftSyntax

extension AccessorDeclSyntax {
  @_spi(Diagnostics)
  public enum AccessorSpecifierOptions: TokenSpecSet {
    case get
    case set
    case didSet
    case willSet
    case unsafeAddress
    case addressWithOwner
    case addressWithNativeOwner
    case unsafeMutableAddress
    case mutableAddressWithOwner
    case mutableAddressWithNativeOwner
    case _read
    case _modify
    case `init`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.getKeyword):
        self = .get
      case TokenSpec(.setKeyword):
        self = .set
      case TokenSpec(.didSetKeyword):
        self = .didSet
      case TokenSpec(.willSetKeyword):
        self = .willSet
      case TokenSpec(.unsafeAddressKeyword):
        self = .unsafeAddress
      case TokenSpec(.addressWithOwnerKeyword):
        self = .addressWithOwner
      case TokenSpec(.addressWithNativeOwnerKeyword):
        self = .addressWithNativeOwner
      case TokenSpec(.unsafeMutableAddressKeyword):
        self = .unsafeMutableAddress
      case TokenSpec(.mutableAddressWithOwnerKeyword):
        self = .mutableAddressWithOwner
      case TokenSpec(.mutableAddressWithNativeOwnerKeyword):
        self = .mutableAddressWithNativeOwner
      case TokenSpec(._readKeyword):
        self = ._read
      case TokenSpec(._modifyKeyword):
        self = ._modify
      case TokenSpec(.initKeyword):
        self = .`init`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .get:
        return .getKeyword
      case .set:
        return .setKeyword
      case .didSet:
        return .didSetKeyword
      case .willSet:
        return .willSetKeyword
      case .unsafeAddress:
        return .unsafeAddressKeyword
      case .addressWithOwner:
        return .addressWithOwnerKeyword
      case .addressWithNativeOwner:
        return .addressWithNativeOwnerKeyword
      case .unsafeMutableAddress:
        return .unsafeMutableAddressKeyword
      case .mutableAddressWithOwner:
        return .mutableAddressWithOwnerKeyword
      case .mutableAddressWithNativeOwner:
        return .mutableAddressWithNativeOwnerKeyword
      case ._read:
        return ._readKeyword
      case ._modify:
        return ._modifyKeyword
      case .`init`:
        return .initKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .get:
        return .keyword(.get)
      case .set:
        return .keyword(.set)
      case .didSet:
        return .keyword(.didSet)
      case .willSet:
        return .keyword(.willSet)
      case .unsafeAddress:
        return .keyword(.unsafeAddress)
      case .addressWithOwner:
        return .keyword(.addressWithOwner)
      case .addressWithNativeOwner:
        return .keyword(.addressWithNativeOwner)
      case .unsafeMutableAddress:
        return .keyword(.unsafeMutableAddress)
      case .mutableAddressWithOwner:
        return .keyword(.mutableAddressWithOwner)
      case .mutableAddressWithNativeOwner:
        return .keyword(.mutableAddressWithNativeOwner)
      case ._read:
        return .keyword(._read)
      case ._modify:
        return .keyword(._modify)
      case .`init`:
        return .keyword(.`init`)
      }
    }
  }
}

extension AsExprSyntax {
  @_spi(Diagnostics)
  public enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension AttributedTypeSyntax {
  @_spi(Diagnostics)
  public enum SpecifierOptions: TokenSpecSet {
    case `inout`
    case __shared
    case __owned
    case isolated
    case _const
    case borrowing
    case consuming
    @_spi(ExperimentalLanguageFeatures)
    case _resultDependsOn
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.inoutKeyword):
        self = .inout
      case TokenSpec(.__sharedKeyword):
        self = .__shared
      case TokenSpec(.__ownedKeyword):
        self = .__owned
      case TokenSpec(.isolatedKeyword):
        self = .isolated
      case TokenSpec(._constKeyword):
        self = ._const
      case TokenSpec(.borrowingKeyword):
        self = .borrowing
      case TokenSpec(.consumingKeyword):
        self = .consuming
      case TokenSpec(._resultDependsOnKeyword) where experimentalFeatures.contains(.nonEscapableTypes):
        self = ._resultDependsOn
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .inout:
        return .inoutKeyword
      case .__shared:
        return .__sharedKeyword
      case .__owned:
        return .__ownedKeyword
      case .isolated:
        return .isolatedKeyword
      case ._const:
        return ._constKeyword
      case .borrowing:
        return .borrowingKeyword
      case .consuming:
        return .consumingKeyword
      case ._resultDependsOn:
        return ._resultDependsOnKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .inout:
        return .keyword(.inout)
      case .__shared:
        return .keyword(.__shared)
      case .__owned:
        return .keyword(.__owned)
      case .isolated:
        return .keyword(.isolated)
      case ._const:
        return .keyword(._const)
      case .borrowing:
        return .keyword(.borrowing)
      case .consuming:
        return .keyword(.consuming)
      case ._resultDependsOn:
        return .keyword(._resultDependsOn)
      }
    }
  }
}

extension AvailabilityConditionSyntax {
  @_spi(Diagnostics)
  public enum AvailabilityKeywordOptions: TokenSpecSet {
    case poundAvailable
    case poundUnavailable
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.poundAvailable):
        self = .poundAvailable
      case TokenSpec(.poundUnavailable):
        self = .poundUnavailable
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .poundAvailable:
        return .poundAvailable
      case .poundUnavailable:
        return .poundUnavailable
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .poundAvailable:
        return .poundAvailableToken()
      case .poundUnavailable:
        return .poundUnavailableToken()
      }
    }
  }
}

extension AvailabilityLabeledArgumentSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case message
    case renamed
    case introduced
    case obsoleted
    case deprecated
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.messageKeyword):
        self = .message
      case TokenSpec(.renamedKeyword):
        self = .renamed
      case TokenSpec(.introducedKeyword):
        self = .introduced
      case TokenSpec(.obsoletedKeyword):
        self = .obsoleted
      case TokenSpec(.deprecatedKeyword):
        self = .deprecated
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .message:
        return .messageKeyword
      case .renamed:
        return .renamedKeyword
      case .introduced:
        return .introducedKeyword
      case .obsoleted:
        return .obsoletedKeyword
      case .deprecated:
        return .deprecatedKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .message:
        return .keyword(.message)
      case .renamed:
        return .keyword(.renamed)
      case .introduced:
        return .keyword(.introduced)
      case .obsoleted:
        return .keyword(.obsoleted)
      case .deprecated:
        return .keyword(.deprecated)
      }
    }
  }
}

extension BooleanLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum LiteralOptions: TokenSpecSet {
    case `true`
    case `false`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.trueKeyword):
        self = .true
      case TokenSpec(.falseKeyword):
        self = .false
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .true:
        return .trueKeyword
      case .false:
        return .falseKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .true:
        return .keyword(.true)
      case .false:
        return .keyword(.false)
      }
    }
  }
}

extension CanImportVersionInfoSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case _version
    case _underlyingVersion
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(._versionKeyword):
        self = ._version
      case TokenSpec(._underlyingVersionKeyword):
        self = ._underlyingVersion
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._version:
        return ._versionKeyword
      case ._underlyingVersion:
        return ._underlyingVersionKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case ._version:
        return .keyword(._version)
      case ._underlyingVersion:
        return .keyword(._underlyingVersion)
      }
    }
  }
}

extension ClosureCaptureSpecifierSyntax {
  @_spi(Diagnostics)
  public enum SpecifierOptions: TokenSpecSet {
    case weak
    case unowned
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.weakKeyword):
        self = .weak
      case TokenSpec(.unownedKeyword):
        self = .unowned
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .weak:
        return .weakKeyword
      case .unowned:
        return .unownedKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .weak:
        return .keyword(.weak)
      case .unowned:
        return .keyword(.unowned)
      }
    }
  }
}

extension ClosureCaptureSpecifierSyntax {
  @_spi(Diagnostics)
  public enum DetailOptions: TokenSpecSet {
    case safe
    case unsafe
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.safeKeyword):
        self = .safe
      case TokenSpec(.unsafeKeyword):
        self = .unsafe
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .safe:
        return .safeKeyword
      case .unsafe:
        return .unsafeKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .safe:
        return .keyword(.safe)
      case .unsafe:
        return .keyword(.unsafe)
      }
    }
  }
}

extension ClosureParameterSyntax {
  @_spi(Diagnostics)
  public enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension ClosureParameterSyntax {
  @_spi(Diagnostics)
  public enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension ClosureShorthandParameterSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension ConsumeExprSyntax {
  @_spi(Diagnostics)
  public enum ConsumeKeywordOptions: TokenSpecSet {
    case _move
    case consume
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(._moveKeyword):
        self = ._move
      case TokenSpec(.consumeKeyword):
        self = .consume
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._move:
        return ._moveKeyword
      case .consume:
        return .consumeKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case ._move:
        return .keyword(._move)
      case .consume:
        return .keyword(.consume)
      }
    }
  }
}

extension DeclModifierSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case __consuming
    case __setter_access
    case _const
    case _local
    case actor
    case async
    case borrowing
    case `class`
    case consuming
    case convenience
    case distributed
    case dynamic
    case `fileprivate`
    case final
    case indirect
    case infix
    case `internal`
    case isolated
    case lazy
    case mutating
    case nonisolated
    case nonmutating
    case open
    case optional
    case override
    case package
    case postfix
    case prefix
    case `private`
    case `public`
    case reasync
    @_spi(ExperimentalLanguageFeatures)
    case _resultDependsOnSelf
    case required
    case `static`
    case unowned
    case weak
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.__consumingKeyword):
        self = .__consuming
      case TokenSpec(.__setter_accessKeyword):
        self = .__setter_access
      case TokenSpec(._constKeyword):
        self = ._const
      case TokenSpec(._localKeyword):
        self = ._local
      case TokenSpec(.actorKeyword):
        self = .actor
      case TokenSpec(.asyncKeyword):
        self = .async
      case TokenSpec(.borrowingKeyword):
        self = .borrowing
      case TokenSpec(.classKeyword):
        self = .class
      case TokenSpec(.consumingKeyword):
        self = .consuming
      case TokenSpec(.convenienceKeyword):
        self = .convenience
      case TokenSpec(.distributedKeyword):
        self = .distributed
      case TokenSpec(.dynamicKeyword):
        self = .dynamic
      case TokenSpec(.fileprivateKeyword):
        self = .fileprivate
      case TokenSpec(.finalKeyword):
        self = .final
      case TokenSpec(.indirectKeyword):
        self = .indirect
      case TokenSpec(.infixKeyword):
        self = .infix
      case TokenSpec(.internalKeyword):
        self = .internal
      case TokenSpec(.isolatedKeyword):
        self = .isolated
      case TokenSpec(.lazyKeyword):
        self = .lazy
      case TokenSpec(.mutatingKeyword):
        self = .mutating
      case TokenSpec(.nonisolatedKeyword):
        self = .nonisolated
      case TokenSpec(.nonmutatingKeyword):
        self = .nonmutating
      case TokenSpec(.openKeyword):
        self = .open
      case TokenSpec(.optionalKeyword):
        self = .optional
      case TokenSpec(.overrideKeyword):
        self = .override
      case TokenSpec(.packageKeyword):
        self = .package
      case TokenSpec(.postfixKeyword):
        self = .postfix
      case TokenSpec(.prefixKeyword):
        self = .prefix
      case TokenSpec(.privateKeyword):
        self = .private
      case TokenSpec(.publicKeyword):
        self = .public
      case TokenSpec(.reasyncKeyword):
        self = .reasync
      case TokenSpec(._resultDependsOnSelfKeyword) where experimentalFeatures.contains(.nonEscapableTypes):
        self = ._resultDependsOnSelf
      case TokenSpec(.requiredKeyword):
        self = .required
      case TokenSpec(.staticKeyword):
        self = .static
      case TokenSpec(.unownedKeyword):
        self = .unowned
      case TokenSpec(.weakKeyword):
        self = .weak
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .__consuming:
        return .__consumingKeyword
      case .__setter_access:
        return .__setter_accessKeyword
      case ._const:
        return ._constKeyword
      case ._local:
        return ._localKeyword
      case .actor:
        return .actorKeyword
      case .async:
        return .asyncKeyword
      case .borrowing:
        return .borrowingKeyword
      case .class:
        return .classKeyword
      case .consuming:
        return .consumingKeyword
      case .convenience:
        return .convenienceKeyword
      case .distributed:
        return .distributedKeyword
      case .dynamic:
        return .dynamicKeyword
      case .fileprivate:
        return .fileprivateKeyword
      case .final:
        return .finalKeyword
      case .indirect:
        return .indirectKeyword
      case .infix:
        return .infixKeyword
      case .internal:
        return .internalKeyword
      case .isolated:
        return .isolatedKeyword
      case .lazy:
        return .lazyKeyword
      case .mutating:
        return .mutatingKeyword
      case .nonisolated:
        return .nonisolatedKeyword
      case .nonmutating:
        return .nonmutatingKeyword
      case .open:
        return .openKeyword
      case .optional:
        return .optionalKeyword
      case .override:
        return .overrideKeyword
      case .package:
        return .packageKeyword
      case .postfix:
        return .postfixKeyword
      case .prefix:
        return .prefixKeyword
      case .private:
        return .privateKeyword
      case .public:
        return .publicKeyword
      case .reasync:
        return .reasyncKeyword
      case ._resultDependsOnSelf:
        return ._resultDependsOnSelfKeyword
      case .required:
        return .requiredKeyword
      case .static:
        return .staticKeyword
      case .unowned:
        return .unownedKeyword
      case .weak:
        return .weakKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .__consuming:
        return .keyword(.__consuming)
      case .__setter_access:
        return .keyword(.__setter_access)
      case ._const:
        return .keyword(._const)
      case ._local:
        return .keyword(._local)
      case .actor:
        return .keyword(.actor)
      case .async:
        return .keyword(.async)
      case .borrowing:
        return .keyword(.borrowing)
      case .class:
        return .keyword(.class)
      case .consuming:
        return .keyword(.consuming)
      case .convenience:
        return .keyword(.convenience)
      case .distributed:
        return .keyword(.distributed)
      case .dynamic:
        return .keyword(.dynamic)
      case .fileprivate:
        return .keyword(.fileprivate)
      case .final:
        return .keyword(.final)
      case .indirect:
        return .keyword(.indirect)
      case .infix:
        return .keyword(.infix)
      case .internal:
        return .keyword(.internal)
      case .isolated:
        return .keyword(.isolated)
      case .lazy:
        return .keyword(.lazy)
      case .mutating:
        return .keyword(.mutating)
      case .nonisolated:
        return .keyword(.nonisolated)
      case .nonmutating:
        return .keyword(.nonmutating)
      case .open:
        return .keyword(.open)
      case .optional:
        return .keyword(.optional)
      case .override:
        return .keyword(.override)
      case .package:
        return .keyword(.package)
      case .postfix:
        return .keyword(.postfix)
      case .prefix:
        return .keyword(.prefix)
      case .private:
        return .keyword(.private)
      case .public:
        return .keyword(.public)
      case .reasync:
        return .keyword(.reasync)
      case ._resultDependsOnSelf:
        return .keyword(._resultDependsOnSelf)
      case .required:
        return .keyword(.required)
      case .static:
        return .keyword(.static)
      case .unowned:
        return .keyword(.unowned)
      case .weak:
        return .keyword(.weak)
      }
    }
  }
}

extension DeclReferenceExprSyntax {
  @_spi(Diagnostics)
  public enum BaseNameOptions: TokenSpecSet {
    case identifier
    case `self`
    case `Self`
    case `init`
    case dollarIdentifier
    case binaryOperator
    case integerLiteral
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.selfKeyword):
        self = .self
      case TokenSpec(.SelfKeyword):
        self = .Self
      case TokenSpec(.initKeyword):
        self = .`init`
      case TokenSpec(.dollarIdentifier):
        self = .dollarIdentifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .self:
        return .selfKeyword
      case .Self:
        return .SelfKeyword
      case .`init`:
        return .initKeyword
      case .dollarIdentifier:
        return .dollarIdentifier
      case .binaryOperator:
        return .binaryOperator
      case .integerLiteral:
        return .integerLiteral
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .self:
        return .keyword(.self)
      case .Self:
        return .keyword(.Self)
      case .`init`:
        return .keyword(.`init`)
      case .dollarIdentifier:
        return .dollarIdentifier("")
      case .binaryOperator:
        return .binaryOperator("")
      case .integerLiteral:
        return .integerLiteral("")
      }
    }
  }
}

extension DerivativeAttributeArgumentsSyntax {
  @_spi(Diagnostics)
  public enum AccessorSpecifierOptions: TokenSpecSet {
    case get
    case set
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.getKeyword):
        self = .get
      case TokenSpec(.setKeyword):
        self = .set
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .get:
        return .getKeyword
      case .set:
        return .setKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .get:
        return .keyword(.get)
      case .set:
        return .keyword(.set)
      }
    }
  }
}

extension DifferentiabilityArgumentSyntax {
  @_spi(Diagnostics)
  public enum ArgumentOptions: TokenSpecSet {
    case identifier
    case integerLiteral
    case `self`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.integerLiteral):
        self = .integerLiteral
      case TokenSpec(.selfKeyword):
        self = .self
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .integerLiteral:
        return .integerLiteral
      case .self:
        return .selfKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .integerLiteral:
        return .integerLiteral("")
      case .self:
        return .keyword(.self)
      }
    }
  }
}

extension DifferentiableAttributeArgumentsSyntax {
  @_spi(Diagnostics)
  public enum KindSpecifierOptions: TokenSpecSet {
    case _forward
    case reverse
    case _linear
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(._forwardKeyword):
        self = ._forward
      case TokenSpec(.reverseKeyword):
        self = .reverse
      case TokenSpec(._linearKeyword):
        self = ._linear
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._forward:
        return ._forwardKeyword
      case .reverse:
        return .reverseKeyword
      case ._linear:
        return ._linearKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case ._forward:
        return .keyword(._forward)
      case .reverse:
        return .keyword(.reverse)
      case ._linear:
        return .keyword(._linear)
      }
    }
  }
}

extension DocumentationAttributeArgumentSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case visibility
    case metadata
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.visibilityKeyword):
        self = .visibility
      case TokenSpec(.metadataKeyword):
        self = .metadata
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .visibility:
        return .visibilityKeyword
      case .metadata:
        return .metadataKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .visibility:
        return .keyword(.visibility)
      case .metadata:
        return .keyword(.metadata)
      }
    }
  }
}

extension EnumCaseParameterSyntax {
  @_spi(Diagnostics)
  public enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension EnumCaseParameterSyntax {
  @_spi(Diagnostics)
  public enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension FunctionDeclSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case binaryOperator
    case prefixOperator
    case postfixOperator
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .binaryOperator:
        return .binaryOperator("")
      case .prefixOperator:
        return .prefixOperator("")
      case .postfixOperator:
        return .postfixOperator("")
      }
    }
  }
}

extension FunctionEffectSpecifiersSyntax {
  @_spi(Diagnostics)
  public enum AsyncSpecifierOptions: TokenSpecSet {
    case async
    case reasync
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.asyncKeyword):
        self = .async
      case TokenSpec(.reasyncKeyword):
        self = .reasync
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .async:
        return .asyncKeyword
      case .reasync:
        return .reasyncKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .async:
        return .keyword(.async)
      case .reasync:
        return .keyword(.reasync)
      }
    }
  }
}

extension FunctionParameterSyntax {
  @_spi(Diagnostics)
  public enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension FunctionParameterSyntax {
  @_spi(Diagnostics)
  public enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension IdentifierPatternSyntax {
  @_spi(Diagnostics)
  public enum IdentifierOptions: TokenSpecSet {
    case identifier
    case `self`
    case `init`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.selfKeyword):
        self = .self
      case TokenSpec(.initKeyword):
        self = .`init`
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .self:
        return .selfKeyword
      case .`init`:
        return .initKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .self:
        return .keyword(.self)
      case .`init`:
        return .keyword(.`init`)
      }
    }
  }
}

extension IdentifierTypeSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case `Self`
    case `Any`
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.SelfKeyword):
        self = .Self
      case TokenSpec(.AnyKeyword):
        self = .Any
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .Self:
        return .SelfKeyword
      case .Any:
        return .AnyKeyword
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .Self:
        return .keyword(.Self)
      case .Any:
        return .keyword(.Any)
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension IfConfigClauseSyntax {
  @_spi(Diagnostics)
  public enum PoundKeywordOptions: TokenSpecSet {
    case poundIf
    case poundElseif
    case poundElse
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.poundIf):
        self = .poundIf
      case TokenSpec(.poundElseif):
        self = .poundElseif
      case TokenSpec(.poundElse):
        self = .poundElse
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .poundIf:
        return .poundIf
      case .poundElseif:
        return .poundElseif
      case .poundElse:
        return .poundElse
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .poundIf:
        return .poundIfToken()
      case .poundElseif:
        return .poundElseifToken()
      case .poundElse:
        return .poundElseToken()
      }
    }
  }
}

extension ImportDeclSyntax {
  @_spi(Diagnostics)
  public enum ImportKindSpecifierOptions: TokenSpecSet {
    case `typealias`
    case `struct`
    case `class`
    case `enum`
    case `protocol`
    case `var`
    case `let`
    case `func`
    case `inout`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.typealiasKeyword):
        self = .typealias
      case TokenSpec(.structKeyword):
        self = .struct
      case TokenSpec(.classKeyword):
        self = .class
      case TokenSpec(.enumKeyword):
        self = .enum
      case TokenSpec(.protocolKeyword):
        self = .protocol
      case TokenSpec(.varKeyword):
        self = .var
      case TokenSpec(.letKeyword):
        self = .let
      case TokenSpec(.funcKeyword):
        self = .func
      case TokenSpec(.inoutKeyword):
        self = .inout
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .typealias:
        return .typealiasKeyword
      case .struct:
        return .structKeyword
      case .class:
        return .classKeyword
      case .enum:
        return .enumKeyword
      case .protocol:
        return .protocolKeyword
      case .var:
        return .varKeyword
      case .let:
        return .letKeyword
      case .func:
        return .funcKeyword
      case .inout:
        return .inoutKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .typealias:
        return .keyword(.typealias)
      case .struct:
        return .keyword(.struct)
      case .class:
        return .keyword(.class)
      case .enum:
        return .keyword(.enum)
      case .protocol:
        return .keyword(.protocol)
      case .var:
        return .keyword(.var)
      case .let:
        return .keyword(.let)
      case .func:
        return .keyword(.func)
      case .inout:
        return .keyword(.inout)
      }
    }
  }
}

extension ImportPathComponentSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case binaryOperator
    case prefixOperator
    case postfixOperator
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .binaryOperator:
        return .binaryOperator("")
      case .prefixOperator:
        return .prefixOperator("")
      case .postfixOperator:
        return .postfixOperator("")
      }
    }
  }
}

extension InitializerDeclSyntax {
  @_spi(Diagnostics)
  public enum OptionalMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension KeyPathOptionalComponentSyntax {
  @_spi(Diagnostics)
  public enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension LabeledExprSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension LabeledSpecializeArgumentSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case target
    case availability
    case exported
    case kind
    case spi
    case spiModule
    case available
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.targetKeyword):
        self = .target
      case TokenSpec(.availabilityKeyword):
        self = .availability
      case TokenSpec(.exportedKeyword):
        self = .exported
      case TokenSpec(.kindKeyword):
        self = .kind
      case TokenSpec(.spiKeyword):
        self = .spi
      case TokenSpec(.spiModuleKeyword):
        self = .spiModule
      case TokenSpec(.availableKeyword):
        self = .available
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .target:
        return .targetKeyword
      case .availability:
        return .availabilityKeyword
      case .exported:
        return .exportedKeyword
      case .kind:
        return .kindKeyword
      case .spi:
        return .spiKeyword
      case .spiModule:
        return .spiModuleKeyword
      case .available:
        return .availableKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .target:
        return .keyword(.target)
      case .availability:
        return .keyword(.availability)
      case .exported:
        return .keyword(.exported)
      case .kind:
        return .keyword(.kind)
      case .spi:
        return .keyword(.spi)
      case .spiModule:
        return .keyword(.spiModule)
      case .available:
        return .keyword(.available)
      }
    }
  }
}

extension LayoutRequirementSyntax {
  @_spi(Diagnostics)
  public enum LayoutSpecifierOptions: TokenSpecSet {
    case _Trivial
    case _TrivialAtMost
    case _UnknownLayout
    case _RefCountedObject
    case _NativeRefCountedObject
    case _Class
    case _NativeClass
    case _BridgeObject
    case _TrivialStride
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(._TrivialKeyword):
        self = ._Trivial
      case TokenSpec(._TrivialAtMostKeyword):
        self = ._TrivialAtMost
      case TokenSpec(._UnknownLayoutKeyword):
        self = ._UnknownLayout
      case TokenSpec(._RefCountedObjectKeyword):
        self = ._RefCountedObject
      case TokenSpec(._NativeRefCountedObjectKeyword):
        self = ._NativeRefCountedObject
      case TokenSpec(._ClassKeyword):
        self = ._Class
      case TokenSpec(._NativeClassKeyword):
        self = ._NativeClass
      case TokenSpec(._BridgeObjectKeyword):
        self = ._BridgeObject
      case TokenSpec(._TrivialStrideKeyword):
        self = ._TrivialStride
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case ._Trivial:
        return ._TrivialKeyword
      case ._TrivialAtMost:
        return ._TrivialAtMostKeyword
      case ._UnknownLayout:
        return ._UnknownLayoutKeyword
      case ._RefCountedObject:
        return ._RefCountedObjectKeyword
      case ._NativeRefCountedObject:
        return ._NativeRefCountedObjectKeyword
      case ._Class:
        return ._ClassKeyword
      case ._NativeClass:
        return ._NativeClassKeyword
      case ._BridgeObject:
        return ._BridgeObjectKeyword
      case ._TrivialStride:
        return ._TrivialStrideKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case ._Trivial:
        return .keyword(._Trivial)
      case ._TrivialAtMost:
        return .keyword(._TrivialAtMost)
      case ._UnknownLayout:
        return .keyword(._UnknownLayout)
      case ._RefCountedObject:
        return .keyword(._RefCountedObject)
      case ._NativeRefCountedObject:
        return .keyword(._NativeRefCountedObject)
      case ._Class:
        return .keyword(._Class)
      case ._NativeClass:
        return .keyword(._NativeClass)
      case ._BridgeObject:
        return .keyword(._BridgeObject)
      case ._TrivialStride:
        return .keyword(._TrivialStride)
      }
    }
  }
}

extension MemberTypeSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case identifier
    case `self`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.selfKeyword):
        self = .self
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .self:
        return .selfKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .self:
        return .keyword(.self)
      }
    }
  }
}

extension MetatypeTypeSyntax {
  @_spi(Diagnostics)
  public enum MetatypeSpecifierOptions: TokenSpecSet {
    case `Type`
    case `Protocol`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.TypeKeyword):
        self = .Type
      case TokenSpec(.ProtocolKeyword):
        self = .Protocol
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .Type:
        return .TypeKeyword
      case .Protocol:
        return .ProtocolKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .Type:
        return .keyword(.Type)
      case .Protocol:
        return .keyword(.Protocol)
      }
    }
  }
}

extension MultipleTrailingClosureElementSyntax {
  @_spi(Diagnostics)
  public enum LabelOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension OperatorDeclSyntax {
  @_spi(Diagnostics)
  public enum FixitySpecifierOptions: TokenSpecSet {
    case prefix
    case postfix
    case infix
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.prefixKeyword):
        self = .prefix
      case TokenSpec(.postfixKeyword):
        self = .postfix
      case TokenSpec(.infixKeyword):
        self = .infix
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .prefix:
        return .prefixKeyword
      case .postfix:
        return .postfixKeyword
      case .infix:
        return .infixKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .prefix:
        return .keyword(.prefix)
      case .postfix:
        return .keyword(.postfix)
      case .infix:
        return .keyword(.infix)
      }
    }
  }
}

extension OperatorDeclSyntax {
  @_spi(Diagnostics)
  public enum NameOptions: TokenSpecSet {
    case binaryOperator
    case prefixOperator
    case postfixOperator
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .binaryOperator:
        return .binaryOperator("")
      case .prefixOperator:
        return .prefixOperator("")
      case .postfixOperator:
        return .postfixOperator("")
      }
    }
  }
}

extension OptionalBindingConditionSyntax {
  @_spi(Diagnostics)
  public enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    @_spi(ExperimentalLanguageFeatures)
    case _mutating
    @_spi(ExperimentalLanguageFeatures)
    case _borrowing
    @_spi(ExperimentalLanguageFeatures)
    case _consuming
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.letKeyword):
        self = .let
      case TokenSpec(.varKeyword):
        self = .var
      case TokenSpec(.inoutKeyword):
        self = .inout
      case TokenSpec(._mutatingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._mutating
      case TokenSpec(._borrowingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._borrowing
      case TokenSpec(._consumingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._consuming
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .let:
        return .letKeyword
      case .var:
        return .varKeyword
      case .inout:
        return .inoutKeyword
      case ._mutating:
        return ._mutatingKeyword
      case ._borrowing:
        return ._borrowingKeyword
      case ._consuming:
        return ._consumingKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      }
    }
  }
}

extension PrecedenceGroupAssignmentSyntax {
  @_spi(Diagnostics)
  public enum ValueOptions: TokenSpecSet {
    case `true`
    case `false`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.trueKeyword):
        self = .true
      case TokenSpec(.falseKeyword):
        self = .false
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .true:
        return .trueKeyword
      case .false:
        return .falseKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .true:
        return .keyword(.true)
      case .false:
        return .keyword(.false)
      }
    }
  }
}

extension PrecedenceGroupAssociativitySyntax {
  @_spi(Diagnostics)
  public enum ValueOptions: TokenSpecSet {
    case left
    case right
    case none
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.leftKeyword):
        self = .left
      case TokenSpec(.rightKeyword):
        self = .right
      case TokenSpec(.noneKeyword):
        self = .none
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .left:
        return .leftKeyword
      case .right:
        return .rightKeyword
      case .none:
        return .noneKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .left:
        return .keyword(.left)
      case .right:
        return .keyword(.right)
      case .none:
        return .keyword(.none)
      }
    }
  }
}

extension PrecedenceGroupRelationSyntax {
  @_spi(Diagnostics)
  public enum HigherThanOrLowerThanLabelOptions: TokenSpecSet {
    case higherThan
    case lowerThan
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.higherThanKeyword):
        self = .higherThan
      case TokenSpec(.lowerThanKeyword):
        self = .lowerThan
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .higherThan:
        return .higherThanKeyword
      case .lowerThan:
        return .lowerThanKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .higherThan:
        return .keyword(.higherThan)
      case .lowerThan:
        return .keyword(.lowerThan)
      }
    }
  }
}

extension SameTypeRequirementSyntax {
  @_spi(Diagnostics)
  public enum EqualOptions: TokenSpecSet {
    case binaryOperator
    case prefixOperator
    case postfixOperator
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.binaryOperator):
        self = .binaryOperator
      case TokenSpec(.prefixOperator):
        self = .prefixOperator
      case TokenSpec(.postfixOperator):
        self = .postfixOperator
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .binaryOperator:
        return .binaryOperator
      case .prefixOperator:
        return .prefixOperator
      case .postfixOperator:
        return .postfixOperator
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .binaryOperator:
        return .binaryOperator("")
      case .prefixOperator:
        return .prefixOperator("")
      case .postfixOperator:
        return .postfixOperator("")
      }
    }
  }
}

extension SimpleStringLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum OpeningQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .stringQuote:
        return .stringQuoteToken()
      case .multilineStringQuote:
        return .multilineStringQuoteToken()
      }
    }
  }
}

extension SimpleStringLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum ClosingQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .stringQuote:
        return .stringQuoteToken()
      case .multilineStringQuote:
        return .multilineStringQuoteToken()
      }
    }
  }
}

extension SomeOrAnyTypeSyntax {
  @_spi(Diagnostics)
  public enum SomeOrAnySpecifierOptions: TokenSpecSet {
    case some
    case any
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.someKeyword):
        self = .some
      case TokenSpec(.anyKeyword):
        self = .any
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .some:
        return .someKeyword
      case .any:
        return .anyKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .some:
        return .keyword(.some)
      case .any:
        return .keyword(.any)
      }
    }
  }
}

extension StringLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum OpeningQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote
    case singleQuote
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      case TokenSpec(.singleQuote):
        self = .singleQuote
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      case .singleQuote:
        return .singleQuote
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .stringQuote:
        return .stringQuoteToken()
      case .multilineStringQuote:
        return .multilineStringQuoteToken()
      case .singleQuote:
        return .singleQuoteToken()
      }
    }
  }
}

extension StringLiteralExprSyntax {
  @_spi(Diagnostics)
  public enum ClosingQuoteOptions: TokenSpecSet {
    case stringQuote
    case multilineStringQuote
    case singleQuote
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.stringQuote):
        self = .stringQuote
      case TokenSpec(.multilineStringQuote):
        self = .multilineStringQuote
      case TokenSpec(.singleQuote):
        self = .singleQuote
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .stringQuote:
        return .stringQuote
      case .multilineStringQuote:
        return .multilineStringQuote
      case .singleQuote:
        return .singleQuote
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .stringQuote:
        return .stringQuoteToken()
      case .multilineStringQuote:
        return .multilineStringQuoteToken()
      case .singleQuote:
        return .singleQuoteToken()
      }
    }
  }
}

extension ThrowsClauseSyntax {
  @_spi(Diagnostics)
  public enum ThrowsSpecifierOptions: TokenSpecSet {
    case `throws`
    case `rethrows`
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.throwsKeyword):
        self = .throws
      case TokenSpec(.rethrowsKeyword):
        self = .rethrows
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .throws:
        return .throwsKeyword
      case .rethrows:
        return .rethrowsKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .throws:
        return .keyword(.throws)
      case .rethrows:
        return .keyword(.rethrows)
      }
    }
  }
}

extension TryExprSyntax {
  @_spi(Diagnostics)
  public enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension TupleTypeElementSyntax {
  @_spi(Diagnostics)
  public enum FirstNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension TupleTypeElementSyntax {
  @_spi(Diagnostics)
  public enum SecondNameOptions: TokenSpecSet {
    case identifier
    case wildcard
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.identifier):
        self = .identifier
      case TokenSpec(.wildcard):
        self = .wildcard
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .identifier:
        return .identifier
      case .wildcard:
        return .wildcard
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .identifier:
        return .identifier("")
      case .wildcard:
        return .wildcardToken()
      }
    }
  }
}

extension UnresolvedAsExprSyntax {
  @_spi(Diagnostics)
  public enum QuestionOrExclamationMarkOptions: TokenSpecSet {
    case postfixQuestionMark
    case exclamationMark
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.postfixQuestionMark):
        self = .postfixQuestionMark
      case TokenSpec(.exclamationMark):
        self = .exclamationMark
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMark
      case .exclamationMark:
        return .exclamationMark
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .postfixQuestionMark:
        return .postfixQuestionMarkToken()
      case .exclamationMark:
        return .exclamationMarkToken()
      }
    }
  }
}

extension ValueBindingPatternSyntax {
  @_spi(Diagnostics)
  public enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    @_spi(ExperimentalLanguageFeatures)
    case _mutating
    @_spi(ExperimentalLanguageFeatures)
    case _borrowing
    @_spi(ExperimentalLanguageFeatures)
    case _consuming
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.letKeyword):
        self = .let
      case TokenSpec(.varKeyword):
        self = .var
      case TokenSpec(.inoutKeyword):
        self = .inout
      case TokenSpec(._mutatingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._mutating
      case TokenSpec(._borrowingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._borrowing
      case TokenSpec(._consumingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._consuming
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .let:
        return .letKeyword
      case .var:
        return .varKeyword
      case .inout:
        return .inoutKeyword
      case ._mutating:
        return ._mutatingKeyword
      case ._borrowing:
        return ._borrowingKeyword
      case ._consuming:
        return ._consumingKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      }
    }
  }
}

extension VariableDeclSyntax {
  @_spi(Diagnostics)
  public enum BindingSpecifierOptions: TokenSpecSet {
    case `let`
    case `var`
    case `inout`
    @_spi(ExperimentalLanguageFeatures)
    case _mutating
    @_spi(ExperimentalLanguageFeatures)
    case _borrowing
    @_spi(ExperimentalLanguageFeatures)
    case _consuming
    
    init?(lexeme: Lexer.Lexeme, experimentalFeatures: Parser.ExperimentalFeatures) {
      switch lexeme {
      case TokenSpec(.letKeyword):
        self = .let
      case TokenSpec(.varKeyword):
        self = .var
      case TokenSpec(.inoutKeyword):
        self = .inout
      case TokenSpec(._mutatingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._mutating
      case TokenSpec(._borrowingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._borrowing
      case TokenSpec(._consumingKeyword) where experimentalFeatures.contains(.referenceBindings):
        self = ._consuming
      default:
        return nil
      }
    }
    
    var spec: TokenSpec {
      switch self {
      case .let:
        return .letKeyword
      case .var:
        return .varKeyword
      case .inout:
        return .inoutKeyword
      case ._mutating:
        return ._mutatingKeyword
      case ._borrowing:
        return ._borrowingKeyword
      case ._consuming:
        return ._consumingKeyword
      }
    }
    
    /// Returns a token that satisfies the `TokenSpec` of this case.
    ///
    /// If the token kind of this spec has variable text, e.g. for an identifier, this returns a token with empty text.
    @_spi(Diagnostics)
    public var tokenSyntax: TokenSyntax {
      switch self {
      case .let:
        return .keyword(.let)
      case .var:
        return .keyword(.var)
      case .inout:
        return .keyword(.inout)
      case ._mutating:
        return .keyword(._mutating)
      case ._borrowing:
        return .keyword(._borrowing)
      case ._consuming:
        return .keyword(._consuming)
      }
    }
  }
}
